{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import streamlit as st\n",
    "import shap\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f31e4b5",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ced7b",
   "metadata": {},
   "source": [
    "## Set current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current directory\n",
    "os.chdir(\"/Users/othmanbensouda/Desktop/Capstone project/Data/main_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ec57e",
   "metadata": {},
   "source": [
    "## Main datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0326ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "academics = pd.read_csv(\"Academics.csv\")\n",
    "\n",
    "classes = pd.read_excel(\"SchoolsClasses.xlsx\",sheet_name  = 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "schools =  pd.read_excel(\"SchoolsClasses.xlsx\",sheet_name  = 1)\n",
    "\n",
    "staff = pd.read_csv(\"EnseignantNiveauxClasses.csv\")\n",
    "\n",
    "students = pd.read_csv(\"Demographics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb113e7",
   "metadata": {},
   "source": [
    "## Nomenclature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf689f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "years_nomenclature = pd.read_excel(\"final_data_dictionary.xlsx\",sheet_name = 7, skiprows = 1)\n",
    "\n",
    "subjects_nomenclature = pd.read_excel(\"final_data_dictionary.xlsx\",sheet_name = 8, skiprows= 1)\n",
    "\n",
    "levels_nomenclature = pd.read_excel(\"final_data_dictionary.xlsx\",sheet_name = 9,skiprows= 1)\n",
    "\n",
    "handicap_nomenclature = pd.read_excel(\"final_data_dictionary.xlsx\",sheet_name = 10,skiprows = 1)\n",
    "\n",
    "student_situation_nomenclature = pd.read_excel(\"final_data_dictionary.xlsx\",sheet_name = 11,skiprows= 1)\n",
    "\n",
    "results_nomenclature = pd.read_excel(\"final_data_dictionary.xlsx\",sheet_name = 12,skiprows= 1)\n",
    "\n",
    "scholarship_nomenclature = pd.read_excel(\"final_data_dictionary.xlsx\",sheet_name = 13)\n",
    "\n",
    "position_nomenclature = pd.read_excel(\"final_data_dictionary.xlsx\",sheet_name = 14,skiprows = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87155415",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84bf14",
   "metadata": {},
   "source": [
    "## Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13621984",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31276589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unecessary columns\n",
    "columns_to_drop = [\"CD_etabr\",\"NetabFr\",\"Nbre_Satellites\",\"Superf_etab\",\"Superf_Cour\",\"Cantine_Capacite\",\"Superf_EspVert\",\"Superf_Exten\",\"Cantine_DO\",\"cd_Ass\",\"Cantine_DF\",\"Couvert_place\",\"Internat_Capacite\",\"Internat_DO\",\"Internat_DF\",\"CD_ETAB.1\",\"ll_reg\",\"cd_prov\",\"NombreSurvGenExt\",\"AdresseL\",\"CD_NETAB\",\"CD_Financ\", \"DC_ETAB\", \"DF_ETAB\", \"DistSatEcoM\", \"DistUniteCol\", \"DistColLyc\", \"Eau_Source\",'DO_ETAB', \"Elec_Source\", \"Ass_Source\", \"FP_Bac\"]\n",
    "schools.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14112f",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BE CAREFUL, THERE ARE CLASSES THAT CAN HAVE LOTS OF DIFFERENT LEVELS AND APPEAR MANY TIMES IN THE DATASET, \n",
    "## EVEN THOUGH THEY ARE NOT DUPLICATES PER SE\n",
    "classes.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_occurrences_column(dataframe):\n",
    "    grouped = dataframe.groupby('id_classe')\n",
    "    dataframe['nombre_de_niveaux'] = grouped['id_classe'].transform('count')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = add_occurrences_column(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parity column\n",
    "classes['parite'] = classes['nbr_filles'] / classes['nbr_eleves']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79971aff",
   "metadata": {},
   "source": [
    "# Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with handicap nomenclature\n",
    "students = students.merge(handicap_nomenclature[[\"id_handicap\",\"handicapFr\"]], how = \"left\", left_on = \"id_handicap\", right_on = \"id_handicap\" )\n",
    "# Change NaN to no handicap\n",
    "students[\"handicapFr\"].fillna(\"no handicap\", inplace=True)\n",
    "# Drop id_handicap column and adress\n",
    "students.drop([\"id_handicap\",\"Adress\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change nationality to either Moroccan, other, or NaN\n",
    "students['nationalite'] = np.where((students['nationalite'] != 'MAR') & (~students['nationalite'].isnull()), 'other', students['nationalite'])\n",
    "# Replace Nan by not specified\n",
    "students['nationalite'].fillna('not specified', inplace=True)\n",
    "# Remove accents and convert to lowercase\n",
    "students['Lieu_naissance_fr'] = students['Lieu_naissance_fr'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "students['Lieu_naissance_fr'] = students['Lieu_naissance_fr'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a0686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA for profession_mere and profession_pere\n",
    "students['profession_pere'] = students['profession_pere'].fillna('non_specifie').astype(str)\n",
    "students['profession_mere'] = students['profession_pere'].fillna('non_specifie').astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a98f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HERE, INSTEAD OF HARDCODING, USE CHATGPT API. THIS HAS BEEN DONE WITH CHATGPT\n",
    "\n",
    "jobs_father = {\n",
    "    'Laborer': [\n",
    "        'عامل',\n",
    "        'مياوم',\n",
    "        'عامل فلاحي',\n",
    "        'JOURNALIER',\n",
    "        'OUVRIER',\n",
    "        'عامل يومي',\n",
    "        'عامل بناء',\n",
    "        'fellah',\n",
    "        'عامل فلا حي',\n",
    "        'ouvrier',\n",
    "        'مزارع',\n",
    "        'مياو'\n",
    "    ],\n",
    "    'Trader': [\n",
    "        'تاجر',\n",
    "        'بائع متجول',\n",
    "        'مساعد تاجر',\n",
    "        'بائع',\n",
    "        'تاجر متجول',\n",
    "        'بائع السمك',\n",
    "        'Commerçant',\n",
    "        'بائع خضر',\n",
    "        'بائع سمك'\n",
    "    ],\n",
    "    'Driver': [\n",
    "        'سائق',\n",
    "        'سائق طاكسي',\n",
    "        'سائق شاحنة',\n",
    "        'سائق سيارة أجرة'\n",
    "    ],\n",
    "    'Retired': [\n",
    "        'متقاعد',\n",
    "        'جندي متقاعد',\n",
    "        'عسكري متقاعد',\n",
    "        'متوفى'\n",
    "    ],\n",
    "    'Employee': [\n",
    "        'موظف',\n",
    "        'مستخدم',\n",
    "        'مساعد تقني',\n",
    "        'مستخدم بشركة',\n",
    "        'مدير شركة',\n",
    "        'مدير',\n",
    "        'مسؤول تجاري',\n",
    "        'مساعد صيدلي',\n",
    "        'مدير تجاري',\n",
    "        'مستخدم بشركة',\n",
    "        'مدير مدرسة',\n",
    "        'EMPLOYE'\n",
    "    ],\n",
    "    'Craftsman': [\n",
    "        'خياط',\n",
    "        'نجار',\n",
    "        'صباغ',\n",
    "        'ميكانيكي',\n",
    "        'صانع تقليدي',\n",
    "        'زلايجي',\n",
    "        'لحام',\n",
    "        'حلاق',\n",
    "        'خراز',\n",
    "        'صانع أحذية',\n",
    "        'فندقي',\n",
    "        'صانع',\n",
    "        'فخاري',\n",
    "        'مكانيكي',\n",
    "        'MACON',\n",
    "        'TAILLEUR',\n",
    "        'صانع أسنان'\n",
    "    ],\n",
    "    'Teacher': [\n",
    "        'أستاذ',\n",
    "        'أستاذ جامعي',\n",
    "        'استاذ',\n",
    "        'أستاذ التعليم الابتدائي',\n",
    "        'استاذ التعليم الابتدائي'\n",
    "    ],\n",
    "    'Security': [\n",
    "        'عون سلطة',\n",
    "        'حارس',\n",
    "        'حارس ليلي',\n",
    "        'حارس عمارة',\n",
    "        'حارس امن',\n",
    "        'حارس عام',\n",
    "        'حارس أمن'\n",
    "    ],'Military': [\n",
    "        'جندي',\n",
    "        'عسكري',\n",
    "        'جندي متقاعد',\n",
    "        'عسكري متقاعد',\n",
    "        'SOLDAT',\n",
    "        'القوات المساعدة'\n",
    "    ],\n",
    "    'Worker': [\n",
    "        'بناء',\n",
    "        'جباص',\n",
    "        'دركي',\n",
    "        'مياوم',\n",
    "        'دراز',\n",
    "        'عاطل',\n",
    "        'اجير',\n",
    "        'موطف',\n",
    "        'موسمي',\n",
    "        'مهاجر',\n",
    "        'عمل حر',\n",
    "        'آخر',\n",
    "        'بدون',\n",
    "        'مياوم',\n",
    "        'عامل يومي',\n",
    "        'لاشيء',\n",
    "        'أعمال حرة',\n",
    "        'fonctionnaire',\n",
    "        'موظف',\n",
    "        'RETRAITE',\n",
    "        'PROFESSEUR',\n",
    "        'FONCTIONNAIRE',\n",
    "        'EMPLOYE',\n",
    "        'commercant',\n",
    "        '  عامل',\n",
    "        'commerçant',\n",
    "        'EMPLOYE',\n",
    "        'commercant',\n",
    "        'métier'\n",
    "    ],\n",
    "    'Officer': [\n",
    "        'ضابط',\n",
    "        'ضابط صف',\n",
    "        'ضابط سامي',\n",
    "        'ضابط شرطة',\n",
    "        'مسؤول تجاري',\n",
    "        'ضابط سامي'\n",
    "    ],\n",
    "    'Technician': [\n",
    "        'مهندس',\n",
    "        'تقني',\n",
    "        'ميكانيكي',\n",
    "        'تقني فلاحي',\n",
    "        'مهندس دولة',\n",
    "        'مساعد تقني',\n",
    "        'تقني متخصص',\n",
    "        'إطار بنكي',\n",
    "        'تقني',\n",
    "        'Mécanicien',\n",
    "        'MACON',\n",
    "        'التجارة'\n",
    "    ],\n",
    "    'Healthcare Professional': [\n",
    "        'ممرض',\n",
    "        'طبيب',\n",
    "        'طباخ',\n",
    "        'صيدلي',\n",
    "        'طبيب',\n",
    "        'ممرض',\n",
    "        'أطباء',\n",
    "        'طباخ',\n",
    "        'أخصائي تقويم',\n",
    "        'نفساني',\n",
    "        'ممرضة',\n",
    "        'صيدلاني',\n",
    "        'دكتور',\n",
    "        'طبيب',\n",
    "        'صيدلي',\n",
    "        'طبيب أطفال',\n",
    "        'مسعف',\n",
    "        'مستشفى'\n",
    "    ],\n",
    "    'Retired': [\n",
    "        'متقاعد',\n",
    "        'جندي متقاعد',\n",
    "        'عسكري متقاعد',\n",
    "        'RETRAITE'\n",
    "    ],\n",
    "    'Agriculturist': [\n",
    "        'فلاح',\n",
    "        'عامل فلاحي',\n",
    "        'fellah',\n",
    "        'FELLAH',\n",
    "        'فلاح مياوم',\n",
    "        'مياوم فلاحي',\n",
    "        'فلاح\\t'\n",
    "    ],    'Artisan': [\n",
    "        'مصور',\n",
    "        'موسيقي',\n",
    "        'مقدم',\n",
    "        'ميكانيك',\n",
    "        'كباص',\n",
    "        'صاحب مقهى',\n",
    "        'صانع',\n",
    "        'فخاري',\n",
    "        'صانع أحذية',\n",
    "        'مصمم',\n",
    "        'صانع مجوهرات',\n",
    "        'فنان',\n",
    "        'عامل خزف',\n",
    "        'فنان تشكيلي',\n",
    "        'خياط',\n",
    "        'نجار',\n",
    "        'صباغ',\n",
    "        'ميكانيكي',\n",
    "        'حلاق',\n",
    "        'خراز',\n",
    "        'صانع أثاث',\n",
    "        'فنان تصوير',\n",
    "        'مطرب',\n",
    "        'فنانة',\n",
    "        'مصفف شعر',\n",
    "        'خياطة',\n",
    "        'فنان بصري',\n",
    "        'موسيقار',\n",
    "        'صانع زجاج',\n",
    "        'مصمم أزياء',\n",
    "        'خزاف',\n",
    "        'فنان رقص',\n",
    "        'عازف',\n",
    "        'صانع ساعات',\n",
    "        'فنان تاتو',\n",
    "        'صانع نحاس',\n",
    "        'عازفة',\n",
    "        'فنان منحوتات',\n",
    "        'صانع فخار',\n",
    "        'فنان جرافيك',\n",
    "        'عازفة بيانو',\n",
    "        'صانع سجاد',\n",
    "        'صانع دمى',\n",
    "        'فنان تشكيلي',\n",
    "        'عازف غيتار',\n",
    "        'صانع تحف',\n",
    "        'صانع تحف',\n",
    "        'فنانة رقص',\n",
    "        'معلم رسم',\n",
    "        'عازف كمان',\n",
    "        'صانع أعمال خشبية',\n",
    "        'فنانة جرافيك',\n",
    "        'عازفة كمان',\n",
    "        'صانع مفروشات',\n",
    "        'صانع ألعاب',\n",
    "        'فنان بالونات',\n",
    "        'صانع مجوهرات',\n",
    "        'عازفة بيانو',\n",
    "        'صانع زجاج',\n",
    "        'فنان تصوير',\n",
    "        'صانع ساعات',\n",
    "        'صانع تحف',\n",
    "        'فنان جرافيك',\n",
    "        'صانع سجاد',\n",
    "        'صانع دمى',\n",
    "        'فنان تشكيلي',\n",
    "        'صانع أعمال خشبية',\n",
    "        'عازف كمان',\n",
    "        'صانع مفروشات',\n",
    "        'صانع ألعاب',\n",
    "        'فنان بالونات',\n",
    "        'فنان ماكياج',\n",
    "        'صانع مجوهرات',\n",
    "        'صانع نحاس',\n",
    "        'فنان تشكيلي',\n",
    "        'عازفة بيانو',\n",
    "        'صانع']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_mother = {\n",
    "    'Homemaker/Unemployed': ['ربة بيت', 'ربت بيت', 'ربة  بيت', 'ربــة بــيــت', 'ربــة  بـيــت', 'ربة بية', 'ربة بيث', 'ربة منزل', 'ربت منزل', 'ر بة بيت', 'ربة ربيت', 'ربة بييت', 'ربة', 'ربت البيت', 'ربية بيت', 'ربة   بيت', 'ربة البيت', 'ربةبيت', 'ربــة بـيــت', 'ربة بييت', 'ربة ربيت', 'FEMME AU FOYER', 'FEMME DE FOYER', 'Femme de foyer', 'femme au foyer', 'femme de foyer', 'اشغال البيت', 'اشغال المنزل', 'البيت', 'بدون', 'SANS', 'sans', 'Sans', 'SAN', 'لاشيء', 'لا شيء', 'لاشئ', 'لاشيئ', 'لا شىء', 'لا شئ', 'لاشىء', 'NEANT', 'RIEN', 'بذون', 'بدون مهنة', 'بدزن', '-', 'ب', 'دون', 'يدون'],\n",
    "    'Worker': ['عاملة', 'مياومة', 'منظفة', 'عامل', 'مياوم', 'اعمال حرة', 'فلاح', 'فلاحة', 'حلاقة', 'خادمة', 'نادلة', 'عاملة نظافة', 'عاملة بشركة', 'سائق', 'صانعة تقليدية', 'خياط', 'خيا','طة', 'طرازة', 'مولدة', 'بناء', 'مقاولة', 'حلوانية', 'مؤطرة'],\n",
    "    'Educator': ['أستاذة', 'استاذة', 'معلمة', 'أستاذ', 'مدرسة', 'أستاذة التعليم الابتدائي', 'استاذة التعليم الابتدائي', 'أستاذة جامعية', 'ENSEIGNANTE', 'معلم(ة)'],\n",
    "    'Employee': ['موظفة', 'مستخدمة', 'موظف', 'متصرفة', 'FONCTIONNAIRE'],\n",
    "    'Medical profession': ['ممرضة', 'طبيبة', 'صيدلانية', 'قابلة', 'مساعدة صيدلي'],\n",
    "    'Business': ['تاجرة', 'تاجر', 'مديرة تربوية', 'مديرة', 'مسيرة شركة', 'إطار بنكي'],\n",
    "    'Farmer': ['فلاح', 'فلاحة'],\n",
    "    'Writer': ['كاتبة'],\n",
    "    'Teacher': ['أستادة', 'أستاذة', 'استاذة'],\n",
    "    'Retired': ['متقاعدة'],\n",
    "    'Student': ['طالبة'],\n",
    "    'Manager': ['مديرة', 'مديرة تربوية', 'مسيرة شركة'],\n",
    "    'Driver': ['سائق'],\n",
    "    'Other': ['مربية', 'متوفية', 'متوفاة', 'مطلقة', 'مرافقة', 'زبة بيت', 'عسكرية', 'مولدة', 'عاملة بشركة', 'مقاولة', 'VF? FDJ', 'بة بيت', 'ربة', 'زبة بيت', 'مساعدة اجتماعية', 'COUTURIERE', 'enfoye', 'F£.K', 'مصممة أزياء', 'مؤطرة']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c18a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the words with categories in the students DataFrame\n",
    "for category, words in jobs_mother.items():\n",
    "    students['profession_mere'] = students['profession_mere'].replace(words, category)\n",
    "\n",
    "for category, words in jobs_father.items():\n",
    "    students['profession_pere'] = students['profession_pere'].replace(words, category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4383",
   "metadata": {},
   "source": [
    "# Academics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597aaece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "academics = academics.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e749419",
   "metadata": {},
   "outputs": [],
   "source": [
    "academics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401d3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only from 2015-2016 to 2018-2019 : Remove covid years\n",
    "academics = academics[(academics['id_annee'] >= 8) & (academics['id_annee'] <= 11)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with levels nomenclature to get corresponding nefstat\n",
    "academics = academics.merge(levels_nomenclature[[\"nefstat\",\"CD_CYCLE\",\"id_typeEnseignement\",\"libformatFr\",\"Suffix\"]],how = \"left\", left_on = \"nefstat\", right_on = \"nefstat\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove higher education (CD cycle starting with 4) and Preschool (CD cycle starting with 00)\n",
    "academics = academics[~academics['CD_CYCLE'].astype(str).str.startswith('4')]\n",
    "academics = academics[academics['CD_CYCLE'].astype(str) != '00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba897b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix problem with absences\n",
    "def fix_absences(dataset):\n",
    "    # Group by student, year, and session\n",
    "    grouped = dataset.groupby(['id_eleve', 'id_annee', 'id_session'])\n",
    "    \n",
    "    # Apply the desired calculations to each group\n",
    "    dataset['NbrJourAbsenceAutorise'] = grouped['NbrJourAbsenceAutorise'].transform('max')\n",
    "    dataset['NbrUniteAbsenceAutorise'] = grouped['NbrUniteAbsenceAutorise'].transform('sum')\n",
    "    dataset['NbrJourAbsenceNonAutorise'] = grouped['NbrJourAbsenceNonAutorise'].transform('sum')\n",
    "    dataset['NbrUniteAbsenceNonAutorise'] = grouped['NbrUniteAbsenceNonAutorise'].transform('sum')\n",
    "    \n",
    "    dataset.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_academics = fix_absences(academics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d40ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_academics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_academics = fixed_academics.drop(['nefstat_orientation','MoyenneExam'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_academics['id_typeBourse'] = fixed_academics['id_typeBourse'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893bd482",
   "metadata": {},
   "source": [
    "# Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose the dataset of high school students present in year 10\n",
    "school_students_id = fixed_academics[(fixed_academics[\"CD_CYCLE\"].isin(['2A','3A'])) & (fixed_academics[\"id_annee\"] == 10) & (fixed_academics[\"id_session\"] == 2) & (~fixed_academics[\"MoynneCC\"].isnull())][\"id_eleve\"]\n",
    "school_dataset_academics = fixed_academics[fixed_academics['id_eleve'].isin(school_students_id)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b51be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_dataset_academics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there remains students with multiple rows for the same id_session\n",
    "def find_students_with_multiple_rows(dataframe):\n",
    "    # Group the dataframe by 'id_eleve' and 'id_annee', and count the number of rows for each group\n",
    "    grouped_dataframe = dataframe.groupby(['id_eleve', 'id_annee','id_session']).size().reset_index(name='count')\n",
    "\n",
    "    # Filter the groups with more than 3 rows\n",
    "    multiple_rows = grouped_dataframe[grouped_dataframe['count'] > 3]\n",
    "\n",
    "    # Extract the unique student IDs from the filtered groups\n",
    "    student_ids = set(multiple_rows['id_eleve'].unique())\n",
    "\n",
    "    return student_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f29738",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_students_with_multiple_rows(school_dataset_academics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab46ad77",
   "metadata": {},
   "source": [
    "# Merge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24165bf1",
   "metadata": {},
   "source": [
    "## Academics with Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I have to make some modifications to the classes dataframe \n",
    "# Remove nefstat\n",
    "classes_modif = classes.drop(['nefstat','id_annee','cd_etab'], axis=1)\n",
    "classes_modif = classes_modif.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e462743",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_modif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = pd.merge(school_dataset_academics, classes_modif, how=\"left\", left_on=\"id_classe\", right_on = \"id_classe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293bd181",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3ef2c4",
   "metadata": {},
   "source": [
    "# Academics & Classes with Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e379ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = pd.merge(merged_dataset, students, how = \"left\", on = \"id_eleve\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcbdae9",
   "metadata": {},
   "source": [
    "# Academics & Classes & Students with Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = pd.merge(merged_dataset, schools, how = \"left\", left_on = \"cd_etab\", right_on = 'CD_ETAB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c2b1b",
   "metadata": {},
   "source": [
    "# Create Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVE DROPOUTS OF YEAR 10\n",
    "\n",
    "# Filter the dataframe based on conditions\n",
    "remove = merged_dataset[(merged_dataset[\"MoyenneGen\"].isnull()) & (merged_dataset[\"id_annee\"] == 10)]\n",
    "students_to_remove = remove[\"id_eleve\"].unique()\n",
    "\n",
    "# Remove students from the merged_dataset\n",
    "merged_dataset = merged_dataset[~merged_dataset[\"id_eleve\"].isin(students_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb72ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ID of dropouts in year 11\n",
    "def find_dropouts(dataframe):\n",
    "    # Check for students present in year 10 but not in year 11\n",
    "    year10_students = set(dataframe[(dataframe[\"id_annee\"] == 10) &\n",
    "                                    (~dataframe[\"CD_CYCLE\"].str.startswith(\"2BAC\",\"21BAC\")) &\n",
    "                                    (dataframe[\"id_resultat\"] != 1)][\"id_eleve\"])\n",
    "\n",
    "    year11_students = set(dataframe[dataframe[\"id_annee\"] == 11][\"id_eleve\"])\n",
    "    dropout_students = year10_students - year11_students\n",
    "\n",
    "    # Check for students present in year 11 with null MoyenneGen\n",
    "    year11_null_moyenne = set(dataframe[(dataframe[\"id_annee\"] == 11) & (dataframe[\"MoyenneGen\"].isnull())][\"id_eleve\"])\n",
    "    dropout_students.update(year11_null_moyenne)\n",
    "\n",
    "    return dropout_students\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by id_classe and id_annee, and calculate the rank percentile\n",
    "merged_dataset['RankPercentile_semester'] = merged_dataset.groupby(['id_classe', 'id_annee','id_session'])['MoynneCC'].rank(pct=True)\n",
    "merged_dataset['RankPercentile_year'] = merged_dataset.groupby(['id_classe', 'id_annee'])['MoyenneGen'].rank(pct=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dropouts\n",
    "list_dropouts = find_dropouts(merged_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_dropouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset[\"id_eleve\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove year 11\n",
    "merged_dataset = merged_dataset[merged_dataset['id_annee'] != 11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc522af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5083091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop id_situation\n",
    "merged_dataset = merged_dataset.drop(\"id_situation\", axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020afb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55afc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column types and modify them accordinly\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(merged_dataset.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b00eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bools = ['INDHcom','INDHquart','istayssir','MCaRtable','ClubEnv',\n",
    "    'PrescolaireModerne',\n",
    "    'PrimaireGeneral',\n",
    "    'PrimaireOriginel',\n",
    "    'CollegialGeneral',\n",
    "    'CollegialOriginel',\n",
    "    'QualifiantGeneral',\n",
    "    'QualifiantOriginel',\n",
    "    'QualifiantTechnique',\n",
    "    'CPGE',\n",
    "    'BTS',\n",
    "    'ConsGestEtab',\n",
    "    'ConsPedag',\n",
    "    'ConsEnseig',\n",
    "    'ConsClas',\n",
    "    'AssParents',\n",
    "    'AssSportive',\n",
    "    'CoopScolaire',\n",
    "    'Partenariat',\n",
    "    'ClubSante',\n",
    "    'CentreAppui',\n",
    "    'AssEcolReussite',\n",
    "    'ProgrammeTissir','Exist_Internet',\n",
    "    'FP',\n",
    "    'ENF',\n",
    "    'Internat',\n",
    "    'Restauration',\n",
    "    'Cantine',\n",
    "    'Clo_Dur',\n",
    "    'Clo_partie',\n",
    "    'Clo_grillage',\n",
    "    'Clo_bois',\n",
    "    'Clo_autre',\n",
    "    'Clo_sans',\n",
    "    'Const_Dur',\n",
    "    'Const_Prefab',\n",
    "    'Const_Pise',\n",
    "    'Const_Autre'\n",
    "]\n",
    "\n",
    "for category in bools:\n",
    "    merged_dataset[category] = merged_dataset[category].astype(bool)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a95bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['id_eleve',\n",
    "    'id_annee',\n",
    "    'id_resultat',\n",
    "    'id_session',\n",
    "    'id_typeBourse',\n",
    "    'id_genre',\n",
    "    'CD_REG','id_typeEnseignement']\n",
    "\n",
    "for column in objects:\n",
    "    merged_dataset[column] = merged_dataset[column].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each column in my dataset, if the type of the column is int or float, replace nan values by median. if the type is not int nor float, replace nan values by mode\n",
    "\n",
    "for col in merged_dataset.columns:\n",
    "    if merged_dataset[col].dtype in ['int64', 'float64']:\n",
    "        merged_dataset[col].fillna(merged_dataset[col].median(), inplace=True)\n",
    "    else:\n",
    "        merged_dataset[col].fillna(merged_dataset[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where CD_CYCLE is '10'\n",
    "merged_dataset.loc[merged_dataset[\"CD_CYCLE\"] == \"10\", [\"MoynneCC\", \"MoyenneGen\"]] *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14bba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 'period' column to distinguish the lags\n",
    "merged_dataset['period'] = merged_dataset['id_annee'].astype(str) + '_sem_' + merged_dataset['id_session'].astype(str)\n",
    "\n",
    "# Drop 'year' and 'semester' as we no longer need them.\n",
    "merged_dataset.drop(['id_annee', 'id_session'], axis=1, inplace=True)\n",
    "\n",
    "# Pivot the table to create unique students per row and periods as columns\n",
    "pivot = pd.pivot_table(merged_dataset, index='id_eleve', columns='period')\n",
    "\n",
    "# Flatten the multi-index columns and rename\n",
    "pivot.columns = ['_'.join(col) + '_lag' for col in pivot.columns]\n",
    "\n",
    "# Reset the index to convert student_id back to a column\n",
    "pivot = pivot.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8afe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b16fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame index\n",
    "pivot.sort_index(inplace=True)\n",
    "\n",
    "# Then apply forward fill\n",
    "pivot = pivot.ffill()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5287aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd99697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'is_dropout' and initialize it with 0\n",
    "pivot['is_dropout'] = 0\n",
    "\n",
    "# Set 'is_dropout' to 1 for IDs present in 'list_dropouts'\n",
    "pivot.loc[pivot['id_eleve'].isin(list_dropouts), 'is_dropout'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5189ef4",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a92bcdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8705879537677379\n",
      "Confusion Matrix: \n",
      " [[66194  9284]\n",
      " [ 1532  6568]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92     75478\n",
      "           1       0.41      0.81      0.55      8100\n",
      "\n",
      "    accuracy                           0.87     83578\n",
      "   macro avg       0.70      0.84      0.74     83578\n",
      "weighted avg       0.92      0.87      0.89     83578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Let's assume 'pivot' is your final DataFrame and 'dropout' is your target variable\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = pivot.drop('is_dropout', axis=1)\n",
    "y = pivot['is_dropout']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "\n",
    "# Calculate the class imbalance ratio\n",
    "class_counts = y_train.value_counts()\n",
    "imbalance_ratio = class_counts[0] / class_counts[1]\n",
    "\n",
    "# Define hyperparameters manually\n",
    "params = {\n",
    "    'scale_pos_weight': 8\n",
    "}\n",
    "\n",
    "# Train the LightGBM model using specified parameters\n",
    "model = LGBMClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", confusion)\n",
    "print(\"Classification Report: \\n\", report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5a1fb",
   "metadata": {},
   "source": [
    "# XGBoost (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Let's assume 'pivot' is your final DataFrame and 'is_dropout' is your target variable\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = pivot.drop('is_dropout', axis=1)\n",
    "y = pivot['is_dropout']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [20],\n",
    "    'min_child_weight': [1],\n",
    "    'subsample': [0.5],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'gamma': [0.3]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "model = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='recall', cv=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and evaluate the model on the test set\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the best parameters and evaluation metrics\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", confusion)\n",
    "print(\"Classification Report: \\n\", report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c593bd4",
   "metadata": {},
   "source": [
    "# XGBOOST (Scale pos weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86516ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Let's assume 'pivot' is your final DataFrame and 'is_dropout' is your target variable\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = pivot.drop('is_dropout', axis=1)\n",
    "y = pivot['is_dropout']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "\n",
    "# Calculate the class imbalance ratio\n",
    "class_counts = y_train.value_counts()\n",
    "imbalance_ratio = class_counts[0] / class_counts[1]\n",
    "\n",
    "# Define hyperparameters manually\n",
    "params = {\n",
    "    'scale_pos_weight': imbalance_ratio\n",
    "}\n",
    "\n",
    "# Train the XGBoost model using specified parameters\n",
    "model = XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", confusion)\n",
    "print(\"Classification Report: \\n\", report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbb99f",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Let's assume 'pivot' is your final DataFrame and 'dropout' is your target variable\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = pivot.drop('is_dropout', axis=1)\n",
    "y = pivot['is_dropout']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Calculate the class imbalance ratio\n",
    "class_counts = y_train.value_counts()\n",
    "imbalance_ratio = class_counts[0] / class_counts[1]\n",
    "\n",
    "# Train the CatBoost model\n",
    "model = CatBoostClassifier(scale_pos_weight=imbalance_ratio)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c4be4",
   "metadata": {},
   "source": [
    "# Random Forest (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "170291b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.903387031996073\n",
      "Validation Confusion Matrix: \n",
      " [[55817  4653]\n",
      " [ 1842  4915]]\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95     60470\n",
      "           1       0.51      0.73      0.60      6757\n",
      "\n",
      "    accuracy                           0.90     67227\n",
      "   macro avg       0.74      0.83      0.77     67227\n",
      "weighted avg       0.92      0.90      0.91     67227\n",
      "\n",
      "Validation F2 Score:  0.671521477757132\n",
      "Test Accuracy:  0.903387031996073\n",
      "Test Confusion Matrix: \n",
      " [[55817  4653]\n",
      " [ 1842  4915]]\n",
      "Test Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95     60470\n",
      "           1       0.51      0.73      0.60      6757\n",
      "\n",
      "    accuracy                           0.90     67227\n",
      "   macro avg       0.74      0.83      0.77     67227\n",
      "weighted avg       0.92      0.90      0.91     67227\n",
      "\n",
      "Test F2 Score:  0.671521477757132\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score\n",
    "\n",
    "# Assuming 'pivot' is your final DataFrame and 'is_dropout' is your target variable\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = pivot.drop('is_dropout', axis=1)\n",
    "y = pivot['is_dropout']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Apply standard scaling\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "\n",
    "# Apply SMOTE on the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Now you can fit the model on the training data\n",
    "model = RandomForestClassifier(random_state=45, class_weight=\"balanced\")\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the validation set with adjusted threshold\n",
    "y_val_pred_proba = model.predict_proba(X_test_scaled)\n",
    "y_val_pred = (y_val_pred_proba[:, 1] >= 0.4).astype(int)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "accuracy_val = accuracy_score(y_test, y_val_pred)\n",
    "confusion_val = confusion_matrix(y_test, y_val_pred)\n",
    "report_val = classification_report(y_test, y_val_pred)\n",
    "\n",
    "# Calculate the F2 score on the validation set\n",
    "f2_val = fbeta_score(y_test, y_val_pred, beta=2)\n",
    "\n",
    "# Print the evaluation metrics for the validation set\n",
    "print(\"Validation Accuracy: \", accuracy_val)\n",
    "print(\"Validation Confusion Matrix: \\n\", confusion_val)\n",
    "print(\"Validation Classification Report: \\n\", report_val)\n",
    "print(\"Validation F2 Score: \", f2_val)\n",
    "\n",
    "# Predict on the test set with adjusted threshold\n",
    "y_test_pred_proba = model.predict_proba(X_test_scaled)\n",
    "y_test_pred = (y_test_pred_proba[:, 1] >= 0.4).astype(int)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "confusion_test = confusion_matrix(y_test, y_test_pred)\n",
    "report_test = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the F2 score on the test set\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Print the evaluation metrics for the test set\n",
    "print(\"Test Accuracy: \", accuracy_test)\n",
    "print(\"Test Confusion Matrix: \\n\", confusion_test)\n",
    "print(\"Test Classification Report: \\n\", report_test)\n",
    "print(\"Test F2 Score: \", f2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3c4d4",
   "metadata": {},
   "source": [
    "# Random Forest (Class weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ff3fbb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.903387031996073\n",
      "Validation Confusion Matrix: \n",
      " [[55817  4653]\n",
      " [ 1842  4915]]\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95     60470\n",
      "           1       0.51      0.73      0.60      6757\n",
      "\n",
      "    accuracy                           0.90     67227\n",
      "   macro avg       0.74      0.83      0.77     67227\n",
      "weighted avg       0.92      0.90      0.91     67227\n",
      "\n",
      "Validation F2 Score:  0.671521477757132\n",
      "Test Accuracy:  0.903387031996073\n",
      "Test Confusion Matrix: \n",
      " [[55817  4653]\n",
      " [ 1842  4915]]\n",
      "Test Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95     60470\n",
      "           1       0.51      0.73      0.60      6757\n",
      "\n",
      "    accuracy                           0.90     67227\n",
      "   macro avg       0.74      0.83      0.77     67227\n",
      "weighted avg       0.92      0.90      0.91     67227\n",
      "\n",
      "Test F2 Score:  0.671521477757132\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score\n",
    "\n",
    "# Assuming 'pivot' is your final DataFrame and 'is_dropout' is your target variable\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = pivot.drop('is_dropout', axis=1)\n",
    "y = pivot['is_dropout']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Apply standard scaling\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "\n",
    "# Apply SMOTE on the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Now you can fit the model on the training data\n",
    "class_counts = y_train_res.value_counts()\n",
    "imbalance_ratio = class_counts[0] / class_counts[1]\n",
    "class_weights = {0: 1, 1: imbalance_ratio}\n",
    "model = RandomForestClassifier(random_state=45, class_weight=class_weights)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the validation set with adjusted threshold\n",
    "y_val_pred_proba = model.predict_proba(X_test_scaled)\n",
    "y_val_pred = (y_val_pred_proba[:, 1] >= 0.4).astype(int)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "accuracy_val = accuracy_score(y_test, y_val_pred)\n",
    "confusion_val = confusion_matrix(y_test, y_val_pred)\n",
    "report_val = classification_report(y_test, y_val_pred)\n",
    "\n",
    "# Calculate the F2 score on the validation set\n",
    "f2_val = fbeta_score(y_test, y_val_pred, beta=2)\n",
    "\n",
    "# Print the evaluation metrics for the validation set\n",
    "print(\"Validation Accuracy: \", accuracy_val)\n",
    "print(\"Validation Confusion Matrix: \\n\", confusion_val)\n",
    "print(\"Validation Classification Report: \\n\", report_val)\n",
    "print(\"Validation F2 Score: \", f2_val)\n",
    "\n",
    "# Predict on the test set with adjusted threshold\n",
    "y_test_pred_proba = model.predict_proba(X_test_scaled)\n",
    "y_test_pred = (y_test_pred_proba[:, 1] >= 0.4).astype(int)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "confusion_test = confusion_matrix(y_test, y_test_pred)\n",
    "report_test = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the F2 score on the test set\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Print the evaluation metrics for the test set\n",
    "print(\"Test Accuracy: \", accuracy_test)\n",
    "print(\"Test Confusion Matrix: \\n\", confusion_test)\n",
    "print(\"Test Classification Report: \\n\", report_test)\n",
    "print(\"Test F2 Score: \", f2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4838f",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0477a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8314218989394142\n",
      "Validation Confusion Matrix: \n",
      " [[50553  9917]\n",
      " [ 1416  5341]]\n",
      "Validation Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90     60470\n",
      "           1       0.35      0.79      0.49      6757\n",
      "\n",
      "    accuracy                           0.83     67227\n",
      "   macro avg       0.66      0.81      0.69     67227\n",
      "weighted avg       0.91      0.83      0.86     67227\n",
      "\n",
      "Validation F2 Score:  0.6315328950480065\n",
      "Test Accuracy:  0.8314218989394142\n",
      "Test Confusion Matrix: \n",
      " [[50553  9917]\n",
      " [ 1416  5341]]\n",
      "Test Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90     60470\n",
      "           1       0.35      0.79      0.49      6757\n",
      "\n",
      "    accuracy                           0.83     67227\n",
      "   macro avg       0.66      0.81      0.69     67227\n",
      "weighted avg       0.91      0.83      0.86     67227\n",
      "\n",
      "Test F2 Score:  0.6315328950480065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score\n",
    "\n",
    "# Assuming 'pivot' is your final DataFrame and 'is_dropout' is your target variable\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = pivot.drop('is_dropout', axis=1)\n",
    "y = pivot['is_dropout']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Apply standard scaling\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "\n",
    "# Apply SMOTE on the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Now you can fit the model on the training data with L1 regularization\n",
    "model = LogisticRegression(penalty='l2', random_state=45)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "accuracy_val = accuracy_score(y_test, y_val_pred)\n",
    "confusion_val = confusion_matrix(y_test, y_val_pred)\n",
    "report_val = classification_report(y_test, y_val_pred)\n",
    "\n",
    "# Calculate the F2 score on the validation set\n",
    "f2_val = fbeta_score(y_test, y_val_pred, beta=2)\n",
    "\n",
    "# Print the evaluation metrics for the validation set\n",
    "print(\"Validation Accuracy: \", accuracy_val)\n",
    "print(\"Validation Confusion Matrix: \\n\", confusion_val)\n",
    "print(\"Validation Classification Report: \\n\", report_val)\n",
    "print(\"Validation F2 Score: \", f2_val)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "confusion_test = confusion_matrix(y_test, y_test_pred)\n",
    "report_test = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the F2 score on the test set\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Print the evaluation metrics for the test set\n",
    "print(\"Test Accuracy: \", accuracy_test)\n",
    "print(\"Test Confusion Matrix: \\n\", confusion_test)\n",
    "print(\"Test Classification Report: \\n\", report_test)\n",
    "print(\"Test F2 Score: \", f2_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea500a0",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Assuming 'data' is your input DataFrame with the target column 'is_dropout'\n",
    "\n",
    "# Identify the categorical columns based on their data types\n",
    "categorical_cols = data.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Identify the numeric columns based on their data types\n",
    "numeric_cols = data.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data.drop('is_dropout', axis=1)\n",
    "y = data['is_dropout']\n",
    "\n",
    "# Perform one-hot encoding on the categorical columns\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols)\n",
    "\n",
    "# Apply MinMaxScaler on the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded[numeric_cols])\n",
    "\n",
    "# Combine the scaled numeric features with the encoded categorical features\n",
    "X_final = pd.concat([pd.DataFrame(X_scaled, columns=numeric_cols), X_encoded.drop(numeric_cols, axis=1)], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Apply SMOTE on the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_res, y_train_res, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix: \\n\", confusion)\n",
    "print(\"Classification Report: \\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84320e5f",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4592b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming 'pivot' is your final DataFrame and 'is_dropout' is your target variable\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = pivot.drop('is_dropout', axis=1)\n",
    "y = pivot['is_dropout']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Apply standard scaling\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "\n",
    "# Apply SMOTE on the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Calculate the class imbalance ratio\n",
    "class_counts = y_train_res.value_counts()\n",
    "imbalance_ratio = class_counts[0] / class_counts[1]\n",
    "\n",
    "# Define the class weights\n",
    "class_weights = {0: 1.0, 1: imbalance_ratio}\n",
    "\n",
    "# Now you can fit the model on the training data\n",
    "model = SVC(class_weight=class_weights, random_state=45)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "accuracy_val = accuracy_score(y_test, y_val_pred)\n",
    "confusion_val = confusion_matrix(y_test, y_val_pred)\n",
    "report_val = classification_report(y_test, y_val_pred)\n",
    "\n",
    "# Calculate the F2 score on the validation set\n",
    "f2_val = fbeta_score(y_test, y_val_pred, beta=2)\n",
    "\n",
    "# Print the evaluation metrics for the validation set\n",
    "print(\"Validation Accuracy: \", accuracy_val)\n",
    "print(\"Validation Confusion Matrix: \\n\", confusion_val)\n",
    "print(\"Validation Classification Report: \\n\", report_val)\n",
    "print(\"Validation F2 Score: \", f2_val)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "confusion_test = confusion_matrix(y_test, y_test_pred)\n",
    "report_test = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the F2 score on the test set\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Print the evaluation metrics for the test set\n",
    "print(\"Test Accuracy: \", accuracy_test)\n",
    "print(\"Test Confusion Matrix: \\n\", confusion_test)\n",
    "print(\"Test Classification Report: \\n\", report_test)\n",
    "print(\"Test F2 Score: \", f2_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
